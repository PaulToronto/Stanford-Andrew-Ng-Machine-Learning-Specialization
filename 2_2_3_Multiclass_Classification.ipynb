{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyOwNmWvoB0evQT8LYea+Ebf",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/PaulToronto/Stanford-Andrew-Ng-Machine-Learning-Specialization/blob/main/2_2_3_Multiclass_Classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2.2.3 Multiclass Classification"
      ],
      "metadata": {
        "id": "AVlHJXsdqPox"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Imports"
      ],
      "metadata": {
        "id": "1RA8nhFEqTTR"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hgxEr2yxqHn1"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2.2.3.1 Multiclass\n",
        "\n",
        "Target, $y$, can take on **more than two** possible values\n",
        "\n",
        "<img src='https://drive.google.com/uc?export=view&id=1akw0YgvtT5dRBMH1kX1-n4FEyXuhnLTL'>\n",
        "\n",
        "### Examples\n",
        "\n",
        "- MNIST: could be any one of 10 digits\n",
        "- Trying to classify whether patients have any of five different possible diseases\n",
        "- Visual inspection of part defects in a factory\n",
        " - scratch, discoloration, chip defect"
      ],
      "metadata": {
        "id": "rXLmAXBiqVwC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2.2.3.2 Softmax"
      ],
      "metadata": {
        "id": "nU9rLXDPube4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The **Softmax regression algorithm** is a generalization of **logistic regression**.\n",
        "\n",
        "<img src='https://drive.google.com/uc?export=view&id=10lKA9fxtJWQIENs-LXKkIxajuut25eec'>\n",
        "\n",
        "- If you apply softmax regression with $n = 2$ it computes the same thing as logistic regression.\n",
        " - The parameters end up being a little bit different, but it reduces to a logistic regression model"
      ],
      "metadata": {
        "id": "benuh9wMviwU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Softmax Cost Function\n",
        "\n",
        "<img src='https://drive.google.com/uc?export=view&id=1itSB-E4kiInMQkOClEznl0uuGunvZpTW'>"
      ],
      "metadata": {
        "id": "Cpqcjy0-0Oe7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2.2.3.3 Neural Network with Softmax output\n",
        "\n",
        "Essentially, we take the Softmax regression model and put it into the output layer of a neural network."
      ],
      "metadata": {
        "id": "-6d93HYw0wKm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Previously, we did handwritten digit recognition with just two classes.\n",
        "\n",
        "<img src='https://drive.google.com/uc?export=view&id=1JDkX0dONTpAPLr6SaqEmvSaN1C-l3UzJ'>\n",
        "\n",
        "We can modify this to accomodate 10 digits.\n",
        "\n",
        "<img src='https://drive.google.com/uc?export=view&id=1-OjamBEZL1J7vkCIl-CgM3-MWoO1Dig0'>\n",
        "\n",
        "\n",
        "- The softmax layer or activation function is different from the other activation functions\n",
        " - With the other activation functions, $a_n$ is a function of $z_n$ and only $z_n$\n",
        "   - $a_n = g\\left(z_n\\right)$\n",
        "   - that means we can apply the activation function element-wise\n",
        " - With softmax $a_n$ is a function of all of $z_1, z_2, \\cdots, z_n$ **simultaneously**\n",
        "   - each of the activation values depend on all of the values of $z$\n",
        "   - we can no longer apply the activation function element-wise"
      ],
      "metadata": {
        "id": "9LX_0jX94fm1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### How to implement Softmax in TensorFlow\n",
        "\n",
        "- **NOTE: don't actually use this code, there is a better version, covered in the next section**\n",
        "- As before, there are 3 steps\n",
        "- The loss function is `SparseCategoricalCrossentropy()`\n",
        " - `Sparse` means that the categories are mutually exclusive. A digit can't be a 4 and a 5 simultaneously\n",
        "\n",
        " <img src='https://drive.google.com/uc?export=view&id=1bzIY-6_3DMFDd-W7xMvBMTVetXlvkyFn'>"
      ],
      "metadata": {
        "id": "hqwetJws_HY9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2.2.3.4 Improved implementation of Softmax"
      ],
      "metadata": {
        "id": "UUmhJHtoBlLU"
      }
    }
  ]
}